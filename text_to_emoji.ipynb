{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0a7ce6-99ff-48b2-a74e-2741aade7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will implement a simple pretrained model to predict a emoji \n",
    "# given a sentence. This is a starting level implementation.\n",
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji as em\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db27ae1-7e0f-4ccc-9e49-1d915527251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data via pandas\n",
    "data = pd.read_csv('./emoji_data.csv', header=None) # as there is no header in data\n",
    "# data[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8471509a-e40c-438b-87a8-e0acb2bc9946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üëç'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we can see the data have text and numbers. The numbers represents the \n",
    "# category of the emoji. TO use them, we need emoji librari to create mapping\n",
    "# dictionary\n",
    "# the emoji library has function emojize to print any emoji, such as:\n",
    "em.emojize(':thumbs_up:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7533c07d-4304-42d9-a336-7583fda15246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ':red_heart:',\n",
       " 1: ':baseball:',\n",
       " 2: ':grinning_face_with_big_eyes:',\n",
       " 3: ':disappointed_face:',\n",
       " 4: ':fork_and_knife_with_plate:'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets map the integers values in our data to emojies\n",
    "# lets create a dictionary \n",
    "emoji_dict = {\n",
    "    0:':red_heart:',\n",
    "    1: ':baseball:',\n",
    "    2: ':grinning_face_with_big_eyes:',\n",
    "    3: ':disappointed_face:',\n",
    "    4: ':fork_and_knife_with_plate:'\n",
    "}\n",
    "emoji_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ae717f-ee1a-43dd-a32d-1e335cf09d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('‚ù§Ô∏è', '‚öæ', 'üòû')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defing a function to where we will pass the label (key) and it will\n",
    "# return us the emoji\n",
    "def label_to_emoji(label):\n",
    "    return em.emojize(emoji_dict[label])\n",
    "\n",
    "label_to_emoji(0), label_to_emoji(1), label_to_emoji(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449a86e8-a81d-420f-93c3-ddee8438713d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now lets separate the data from labels - here we will use \n",
    "# x -  as data and y - as labels\n",
    "x = data[0].values\n",
    "y = data[1].values\n",
    "# x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58dc915a-395a-48e7-a08b-056eedee5202",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it is time to use word embedding - I will be using pre-trained word embedding\n",
    "# glove, introduced by stanford researchers\n",
    "# please follow this link to download: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# once it is downloaded: extract it and it will have four files\n",
    "# each file represents the embedding with respect to their dimensions\n",
    "# here, 100d file will be used - lets open it using open()\n",
    "file = open('./glove.6B/glove.6B.100d.txt', encoding='utf8')\n",
    "content = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1436c414-16e1-46aa-9c59-0bcbb4e16559",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# content[:50]\n",
    "# here we can see that against each word there is word vector of 100 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f758f0-bb7d-4ff0-8204-360a591e2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to create a dictionary that will map the word to their \n",
    "# corresponding vector\n",
    "embedding = {}\n",
    "\n",
    "# lets iterate through each line;\n",
    "for line in content:\n",
    "    line = line.split()\n",
    "    \n",
    "    # we are going to map the first word against the remaining vector\n",
    "    embedding[line[0]] = np.array(line[1:], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e112bd5-c081-46fb-abe9-dee33671ce03",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding.keys()) # here we can see that we have 400000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "060d1f67-2192-4b83-b77f-05feaa610ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x1f030de3520>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next thing we have to preprocess the data - converting the data into input \n",
    "# tokens and convert y into one-hot vector\n",
    "# for tokening the input text, a tokenizer function from keras will be used\n",
    "# it will convert each specific word from text into a number and number is \n",
    "# assigned to a order in which that word is appearing in the dictionary\n",
    "# lets initiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "671d10d2-174d-4faa-b8c9-a2d386302d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets fit this onto our dataset\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7121d217-a276-4db8-b1b0-83420802c63b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the output of above line\n",
    "word_to_index = tokenizer.word_index\n",
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f16744-eb64-4b12-ab06-1f982a05c9c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next all words will be converted into a list of tokens\n",
    "x_tokens = tokenizer.texts_to_sequences(x)\n",
    "# x_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee19c801-4fd9-48d8-97d2-80a48e4731b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we cann see that all tokens have arbitrary length -  this cannot be used \n",
    "# directly in the model. we need a fixed length input\n",
    "# we will be using padding to transfer it into a fixed length vector - the fixed\n",
    "# length will be the largest vector of this dataset\n",
    "maxlen = 0\n",
    "for data in x_tokens:\n",
    "    maxlen = max(maxlen, len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cea68f98-9743-4271-8a7c-652cb2bec13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen # the max length of our sentence here is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d03228-38f0-42b4-99df-e5445bc9d403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets padd the x_tokens and called it training data\n",
    "x_train = pad_sequences(x_tokens, maxlen=maxlen, padding='post', truncating='post')\n",
    "# x_train[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "856997e9-3be4-4578-9e5a-4afca8fe78bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the x_data is ready to be used for training\n",
    "# next convert the y into one-hot encoding\n",
    "# as our data contain some values which we  don't need, we need to clean the\n",
    "# data\n",
    "y_ = [(lambda x: x.split()[0][0]) (x) for x in y.tolist()]\n",
    "y = np.array(y_, dtype=object)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aab00ee-240d-4e60-9b8b-892eeb99a068",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets convert it into one-hot, for that, we will be using a builtin \n",
    "# function to_categorical\n",
    "y_train = to_categorical(y)\n",
    "# y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f03773-c08f-4bca-8985-29927a11b4b8",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42964fb9-6596-4898-bf64-993342b27f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are going to use pretrained word embeddings - for that we will pass \n",
    "# matrix to weights parameters in the models. Lets create that matrix\n",
    "# here that matrix will have all the words embedding vectors of all the words in\n",
    "# our dataset\n",
    "# here the rows will be the words and the columns will be the vectors\n",
    "embed_size = 100 # as we are using 100 dimension vector\n",
    "\n",
    "# lets initialize the matrix will zero values\n",
    "embedding_matrix = np.zeros((len(word_to_index)+1, embed_size))\n",
    "\n",
    "# lets iterate over all the words in our embedding dict\n",
    "for word, index in word_to_index.items():\n",
    "    embed_vector = embedding[word]\n",
    "    embedding_matrix[index] = embed_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d3e1c0-ea82-46b8-85bf-23d6428d9ef7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f2d21a3-73f4-4024-8664-dfa2d49a493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create the model now\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_to_index)+1,\n",
    "             output_dim=embed_size,\n",
    "             input_length=maxlen,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False\n",
    "             ),\n",
    "    # next we can specify simple LSTM or RNN layer - first LSTM\n",
    "    LSTM(units=16, return_sequences=True), # return_sequence will make sure to \n",
    "                                            # return the value at each sequence\n",
    "     LSTM(units=10, return_sequences=True),\n",
    "    LSTM(units=4), # we do not have to specify the return_sequence at last layer\n",
    "    Dense(units=5, activation='softmax'),\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e5165ca-dc8d-475e-8dff-c3d7aff10365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 100)           31300     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 16)            7488      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10, 10)            1080      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 4)                 240       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,133\n",
      "Trainable params: 8,833\n",
      "Non-trainable params: 31,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8964706-9564-4a2d-87ca-9a6750430f06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 9s 23ms/step - loss: 1.6063 - accuracy: 0.2951\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5938 - accuracy: 0.3552\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5842 - accuracy: 0.3607\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5752 - accuracy: 0.3060\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.5652 - accuracy: 0.2896\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5536 - accuracy: 0.2896\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.5393 - accuracy: 0.3115\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5180 - accuracy: 0.3279\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.4951 - accuracy: 0.3443\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.4690 - accuracy: 0.3770\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.4408 - accuracy: 0.3934\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.4097 - accuracy: 0.4153\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.3840 - accuracy: 0.4372\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.3527 - accuracy: 0.4536\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.3210 - accuracy: 0.4645\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.2895 - accuracy: 0.4645\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.2497 - accuracy: 0.4809\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.2308 - accuracy: 0.4809\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.1893 - accuracy: 0.4918\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.1616 - accuracy: 0.5137\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1556 - accuracy: 0.5082\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.1395 - accuracy: 0.5246\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1021 - accuracy: 0.5410\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.0818 - accuracy: 0.5738\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.0623 - accuracy: 0.6066\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0442 - accuracy: 0.6612\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0243 - accuracy: 0.6448\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.0105 - accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.9889 - accuracy: 0.6885\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9722 - accuracy: 0.6940\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9562 - accuracy: 0.7486\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9377 - accuracy: 0.7596\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9236 - accuracy: 0.8087\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.9143 - accuracy: 0.7760\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.9500 - accuracy: 0.7486\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8745 - accuracy: 0.8033\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8597 - accuracy: 0.7923\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8228 - accuracy: 0.8251\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8044 - accuracy: 0.8415\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7954 - accuracy: 0.8306\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7823 - accuracy: 0.8525\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7580 - accuracy: 0.8689\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7394 - accuracy: 0.8579\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7217 - accuracy: 0.8689\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6918 - accuracy: 0.9016\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6910 - accuracy: 0.8907\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6841 - accuracy: 0.8689\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7356 - accuracy: 0.8470\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7196 - accuracy: 0.8525\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6950 - accuracy: 0.8579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f062ecc970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97efc00e-2bc8-4ff8-85fd-bb42dfe17a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets test the model - I am going to write the sentences to test\n",
    "test = ['i feel good', 'i feel very bad', \n",
    "        'lets eat dinner']\n",
    "# lets convert the words into padded tokenize sequences\n",
    "test_sequ = tokenizer.texts_to_sequences(test)\n",
    "x_test = pad_sequences(test_sequ, maxlen=maxlen, padding='post', \n",
    "                      truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db3529f-fa86-4e6d-9649-8e13c18249f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.10998087, 0.23925649, 0.45704293, 0.09805621, 0.09566353],\n",
       "       [0.01549632, 0.0602515 , 0.4272157 , 0.4523882 , 0.04464825],\n",
       "       [0.20270593, 0.06507625, 0.08274296, 0.08793829, 0.5615365 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets make the predictions\n",
    "y_predict = model.predict(x_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba79c6f1-5d33-4763-957e-c0532f3fc5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # lets get the index where max value is present\n",
    "y_pred = np.argmax(y_predict, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b0bcc76-815f-4213-87b8-dc0731c8f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel good üòÉ\n",
      "i feel very bad üòû\n",
      "lets eat dinner üçΩÔ∏è\n"
     ]
    }
   ],
   "source": [
    "# we have our tokens, lets see the emojies now\n",
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2dda375-fde6-4200-b11e-62e2a6feed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just an initial level implementation - model is making mistakes\n",
    "# we can use large dataset to improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd06707-87ca-4ea5-8103-c45705cef8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
